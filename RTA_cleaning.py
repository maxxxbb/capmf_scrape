import pandas as pd
import numpy as np
import pytest
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
import time

# This script cleans the Trendy data and creates a panel dataset with the number 
# of active provisions per country and year, while preventing double counting of provisions.
# 
#
#
# The script is tested with a small dataset generated by hand. 

# Script runs around 20 minutes

## 1. Define paths

input_path = r"V:\ENVINFO\BACKUP\STATA\IPAC\CAP\Excel files\1_RawDataCAP\Extension\trenddyadic2022.dta"
output_path = r"V:\ENVINFO\BACKUP\STATA\IPAC\CAP\Excel files\1_RawDataCAP\Extension\RTA_trendy_panel.xlsx"

## 1.1 Define dictionaries of trade blocks and inconsistently named countries

trade_blocks = {
    "ASEAN": [
        "Brunei",
        "Burma (Myanmar)",
        "Cambodia",
        "Timor-Leste",
        "Indonesia",
        "Laos",
        "Malaysia",
        "Philippines",
        "Singapore",
        "Thailand",
        "Vietnam"
    ],
    "CARICOM": [
        "Antigua and Barbuda",
        "Bahamas",
        "Barbados",
        "Belize",
        "Dominica",
        "Jamaica",
        "Grenada",
        "Guyana",
        "Haiti",
        "Montserrat",
        "St. Kitts and Nevis",
        "St. Vincent and the Grenadines",
        "St. Lucia",
        "Suriname",
        "Trinidad and Tobago"
    ],
    "EAC": [
        "Congo, Democratic Republic of the",
        "Republic of Burundi",
        "Republic of Kenya",
        "Republic of Rwanda",
        "Federal Republic of Somalia",
        "Republic of South Sudan",
        "Uganda",
        "Tanzania"
    ],
    "EFTA": [
        "Iceland",
        "Liechtenstein",
        "Norway",
        "Switzerland"
    ],
    "GCC": [
        "Bahrain",
        "Kuwait",
        "Oman",
        "Qatar",
        "Saudi Arabia",
        "United Arab Emirates"
    ],
    "MERCOSUR": [
        "Argentina",
        "Brazil",
        "Paraguay",
        "Uruguay",
        "Venezuela"
    ],
    "SACU": [
        "Botswana",
        "Lesotho",
        "Namibia",
        "South Africa",
        "Swaziland"
    ],
    "Andean Community": [
        "Bolivia",
        "Colombia",
        "Ecuador",
        "Peru"
    ],
    "ACP": [
        "Angola",
        "Antigua and Barbuda",
        "Bahamas",
        "Barbados",
        "Belize",
        "Benin",
        "Botswana",
        "Burkina Faso",
        "Burundi",
        "Cabo Verde",
        "Cameroon",
        "Central African Republic",
        "Chad",
        "Comoros",
        "Congo",
        "Congo, Democratic Republic of the",
        "Cook Islands",
        "Côte d'Ivoire",
        "Cuba",
        "Djibouti",
        "Dominica",
        "Dominican Republic",
        "Equatorial Guinea",
        "Eritrea",
        "Eswatini",
        "Ethiopia",
        "Fiji",
        "Gabon",
        "Gambia",
        "Ghana",
        "Grenada",
        "Guinea",
        "Guinea-Bissau",
        "Guyana",
        "Haiti",
        "Jamaica",
        "Kenya",
        "Kiribati",
        "Lesotho",
        "Liberia",
        "Madagascar",
        "Malawi",
        "Mali",
        "Marshall Islands",
        "Mauritania",
        "Mauritius",
        "Micronesia, Federated States of",
        "Mozambique",
        "Namibia",
        "Nauru",
        "Niger",
        "Nigeria",
        "Niue",
        "Palau",
        "Papua New Guinea",
        "Rwanda",
        "St. Kitts and Nevis",
        "St. Lucia",
        "St. Vincent and the Grenadines",
        "Samoa",
        "Sao Tome and Principe",
        "Senegal",
        "Seychelles",
        "Sierra Leone",
        "Solomon Islands",
        "Somalia",
        "South Africa",
        "Republic of South Sudan",
        "Suriname",
        "Luciania",
        "Timor-Leste",
        "Togo",
        "Tonga",
        "Trinidad and Tobago",
        "Tuvalu",
        "Uganda",
        "Vanuatu",
        "Zambia",
        "Zimbabwe"
    ]
}

replace_dict = {
    "Gambia (Islamic Republic of the)": "Gambia",
    "Guinea Bissau": "Guinea-Bissau",
    "Côte D'Ivoire": "Côte d'Ivoire",
    "Côte d’Ivoire": "Côte d'Ivoire",
    "St. Kitts & Nevis": "St. Kitts and Nevis",
    "St. Vincent & Grenadines": "St. Vincent and the Grenadines",
    "Saint Vincent and the Grenadines": "St. Vincent and the Grenadines",
    "Sudan": "South Sudan",
    "Bolivia (Plurinational State of)": "Bolivia",
    "Sudan ": "South Sudan",
    "Kazakhstan ": "Kazakhstan",
    "Angola ": "Angola",
    "Republic of Burundi": "Burundi",
    "Republic of Kenya": "Kenya",
    "Republic of Rwanda": "Rwanda",
    "Federal Republic of Somalia": "Somalia",
    "Republic of South Sudan": "South Sudan",
    "United Republic of Tanzania": "Tanzania",
    "Tanzania, United Republic of": "Tanzania",
    "St. Kitts and Nevis": "Saint Kitts and Nevis",
    "Saint Lucia": "St. Lucia",
    "Congo, Democratic Republic of the": "Democratic Republic of the Congo",
    "Côte d\x92Ivoire": "Côte d'Ivoire",
    "Micronesia (Federated States of)": "Micronesia, Federated States of",
    "Brunei Darussalam": "Brunei",
    "Lao People's Democratic Republic": "Laos",
    "Viet Nam": "Vietnam",
    "Burma (Myanmar)": "Myanmar",
    "Venezuela, Bolivarian Republic of": "Venezuela",
    "St. Kitts & Nevis": "Saint Kitts and Nevis",
    "Saint Vincent and the Grenadines": "St. Vincent and the Grenadines",
    "Micronesia, Federated States of": "Micronesia (Federated States of)",
    "Monserrat" : "Montserrat",
    "Eswatini" : "Swaziland",
    "Swasiland": "Swaziland"
}



## 2. Define functions
## 2.1. Define test cases
def test_sample_data():
    """
    Creates sameple dataset mimicking trendy data with trade
    agreements for testing purpose


    """

    data = {
        'tradeagreement': ['Trade_1', 'Trade_2', 'Trade_3', 'Trade_4', 'Trade_4', 'Trade_4', 'Trade_5', 'Trade_5'],
        'country1': ['ALB', 'CAN', 'CAN', 'MEX', 'ALB', 'MEX', 'CAN', 'BEL'],
        'country2': ['MEX', 'ALB', 'MEX', 'CAN', 'LUX', 'ALB', 'LUX', 'ALB'],
        'year': [1990, 1990, 1991, 1995, 1995, 1995, 2000, 2000],
        'x1': [1, 1, 1, 1, 0, 1, 0, 1],
        'x2': [0, 0, 1, 1, 1, 0, 1, 0]
    }
    return pd.DataFrame(data)

def test_expected_data():
    """
    Just Testing the function with a small dataset generated by hand.
    Creates fixture data.
    """

    data = {
        'Country': ['ALB', 'ALB', 'ALB', 'ALB', 'ALB', 'ALB', 'ALB', 'ALB', 'ALB', 'ALB', 'ALB',
                    'BEL', 'BEL', 'BEL', 'BEL', 'BEL', 'BEL', 'BEL', 'BEL', 'BEL', 'BEL', 'BEL',
                    'CAN', 'CAN', 'CAN', 'CAN', 'CAN', 'CAN', 'CAN', 'CAN', 'CAN', 'CAN', 'CAN',
                    'MEX', 'MEX', 'MEX', 'MEX', 'MEX', 'MEX', 'MEX', 'MEX', 'MEX', 'MEX', 'MEX',
                    'LUX','LUX','LUX','LUX','LUX','LUX','LUX','LUX','LUX','LUX','LUX'],
        'year': [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
                 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
                 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
                 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
                 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000],
        'sum_x1': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,
                   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 
                   1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
                   1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
                   0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0],
        'sum_x2': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,
                   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
                   0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 
                   0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                   0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2],

    }

    # forward fill data until 2023
    data = pd.DataFrame(data)
    ## add years 2001 to 2023 to the panel data
    years = range(2001, 2024)
    countries = pd.unique(data['Country'])
    panel_data = []
    ## create panel dataframe to later concatenate
    for country in countries:
        for year in years:
            panel_data.append({'Country': country, 'year': year, 'sum_x1': np.nan, 'sum_x2': np.nan})
    panel_data = pd.DataFrame(panel_data)

    # append to the original data
    data = pd.concat([data, panel_data], ignore_index=True)
    data = data.sort_values(by=['Country', 'year']).reset_index(drop=True)
    

    # forward fill nas

    data = data.fillna(method='ffill')
    # convert x columns to int64: all columns which start with x
    x_cols = data.filter(regex='sum_x').columns
    data[x_cols] = data[x_cols].astype('int64')
    
    return data

## 2.2 Define main data cleaning functions


    
def expand_row(row, x_columns,trade_blocks):
    """ Splits up trade blocks and expands dataset for each member country  """
    
    countries1 = trade_blocks.get(row['country1'], [row['country1']])
    countries2 = trade_blocks.get(row['country2'], [row['country2']])
    
    expanded = []
    for c1 in countries1:
        for c2 in countries2:
            expanded_row = [row['tradeagreement'], c1, c2, row['year']]
            expanded_row.extend([row[col] for col in x_columns])
            expanded.append(expanded_row)
    
    return expanded



def split_country_blocks(data, trade_blocks, replace_dict):
    """
    Splits up trade blocks in individual member countries.

    Further renames some countries with inconsistent naming
    
    input:
        data: dataframe with environmental provisions
        trade_blocks: dictionary with trade blocks(keys) and their member countries(values)
        replace_dict: dictionary with inconsistenc country names(keys) and corresponding correct names (values)



    """
    x_columns = [col for col in data.columns if col.startswith('x')]

    # Creating column names for the expanded DataFrame
    expanded_columns = ['tradeagreement', 'country1', 'country2', 'year'] + x_columns

    # Expand the DataFrame
    expanded_rows = []
    for idx, row in data.iterrows():
        expanded_rows.extend(expand_row(row, x_columns,trade_blocks))

    # Create the expanded DataFrame
    expanded_df = pd.DataFrame(expanded_rows, columns=expanded_columns).drop_duplicates()

    # Remove entries where country1 == country2
    filtered_df = expanded_df[expanded_df['country1'] != expanded_df['country2']].reset_index(drop=True)

    # Replace country names using replace_dict
    filtered_df['country1'] = filtered_df['country1'].replace(replace_dict)
    filtered_df['country2'] = filtered_df['country2'].replace(replace_dict)

    return filtered_df


def create_panel_dataset(df):

    """
    Creates panel dataset: per country and year it sums the number of active provisions with distinct countries.
    
    
    """
    years = range(1990, 2024)
    countries = pd.unique(df[['country1', 'country2']].values.ravel('K'))
    panel_data = []

    x_columns = [col for col in df.columns if col.startswith('x')]

    for country in countries:
        for year in years:
            active_treaties = df[((df['country1'] == country) | (df['country2'] == country)) & (df['year'] <= year)].copy()
            active_treaties['country_pair'] = active_treaties.apply(lambda row: tuple(sorted([row['country1'], row['country2']])), axis=1)

            # Find duplicates based on the 'country_pair' column
            duplicate_treaties = active_treaties.duplicated(subset=['country_pair'], keep=False)
            
            # Identify and clean duplicates
            cleaned_duplicates = active_treaties[duplicate_treaties].groupby(['country_pair']).agg({col: 'max' for col in x_columns}).reset_index()

            # Sum non-duplicate and cleaned duplicate provisions
            non_duplicate_treaties = active_treaties[~duplicate_treaties]
            sums = {f'sum_{col}': non_duplicate_treaties[col].sum() + cleaned_duplicates[col].sum() for col in x_columns}
            sums.update({'Country': country, 'year': year})

            panel_data.append(sums)
        print(f"{country} done")
    panel_df = pd.DataFrame(panel_data)
    panel_df = panel_df.sort_values(by=['Country', 'year']).reset_index(drop=True)

    cols = ['Country', 'year'] + [f'sum_{col}' for col in x_columns]
    panel_df = panel_df[cols]

    print("Data cleaning finished")
    return panel_df

## 2.3 Define Test function to see whether double entry handling and creating the panel dataset goes as planned

def test_create_panel_dataset():
    df = test_sample_data()
    expected_df = test_expected_data()
    result = create_panel_dataset(df)
    pd.testing.assert_frame_equal(result, expected_df)


## 2.4 Functions to save panel data as xlsx
def add_readme_to_worksheet(ws):
    """
    Adds a Readme content to the xlsx.
    
    Args:
        ws (openpyxl.worksheet.worksheet.Worksheet): The worksheet to add the Readme content to.
    """

    readme_text = [
        ' This file contains data on regional trade agreement provisions: ',
        ' https://www.chaire-epi.ulaval.ca/en/trend',
        ' The raw data was adjusted to create a panel dataset with the sum of active provisions for each country and year.',
        ' Country: Brazil, Year: 2019, x1:20  , would mean that in 2019 Brazil provision x1 is active in trade agreements.',
        ' with 20 other countries (where duplicates (same provision in multiple treaties) are exluded)'  ,
        ' The script used to clean the data and create this .xlsx can be found at',
        ' \\\\main.oecd.org\\ASgenENV\\ENVINFO\\BACKUP\\STATA\\IPAC\\CAP\\Others\\Scraping_Scripts\\RTA_cleaning.py'
    ]

    for i, line in enumerate(readme_text, start=1):
        ws.cell(row=i, column=1, value=line)
        if 'https://' in line or '\\\\' in line:
            ws.cell(row=i, column=1).hyperlink = line

def save_to_excel(output_path, df):
    """
    Saves the dataframe and Readme content to an Excel file.
    
    Args:
        output_path (str): The path to save the Excel file to.
        df (pd.DataFrame): The dataframe containing the data.
    """
    wb = Workbook()
    ws_readme = wb.active
    ws_readme.title = "Readme"
    ws_data = wb.create_sheet(title="RTA_trendy_panel")

    add_readme_to_worksheet(ws_readme)

    for row in dataframe_to_rows(df, index=False, header=True):
        ws_data.append(row)

    wb.save(output_path)


## 3. Run the script
def main():
    
    # timer
    start_time = time.time()

    # Run the test if it passes - code does what it is supposed to 
    
    test_create_panel_dataset()
    print("Test 1 passed.")
    
    # read data , manipulate it and save it to excel

    data = pd.read_stata(input_path)
    # clean: split up trade blocks and rename countries
    data_c = split_country_blocks(data, trade_blocks, replace_dict)
    # create panel dataset and add up provisions without double countring
    panel = create_panel_dataset(data_c)
    save_to_excel(output_path, panel)
    
    # timer
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Time to clean RTA data: {elapsed_time:.2f} seconds")


if __name__ == "__main__":
    main()





